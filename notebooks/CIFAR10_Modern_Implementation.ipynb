{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Image Classification - Modern Implementation\n",
    "\n",
    "This notebook demonstrates the improved, modular implementation of CIFAR-10 image classification using modern PyTorch practices.\n",
    "\n",
    "## Key Improvements\n",
    "- **Modular Design**: Separated concerns into different modules\n",
    "- **Better Architecture**: Improved CNN with modern techniques\n",
    "- **Configuration Management**: Flexible experiment configuration\n",
    "- **Advanced Training**: Professional training pipeline with monitoring\n",
    "- **Comprehensive Evaluation**: Detailed analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import our custom modules\n",
    "from src.data.dataset import CIFAR10DataModule\n",
    "from src.models.cifar10_cnn import get_model\n",
    "from src.utils.trainer import ModelTrainer\n",
    "from src.utils.visualization import (\n",
    "    show_sample_images, plot_training_history, \n",
    "    plot_confusion_matrix, visualize_predictions\n",
    ")\n",
    "from configs.config import ExperimentConfig, get_quick_config\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup\n",
    "\n",
    "We'll use the modern configuration system to set up our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment configuration\n",
    "config = get_quick_config()  # Quick config for notebook demonstration\n",
    "config.name = \"notebook_demo\"\n",
    "config.description = \"Demonstration of improved CIFAR-10 implementation\"\n",
    "config.training.epochs = 10  # Reduced for demonstration\n",
    "config.data.batch_size = 64\n",
    "config.model.model_name = \"improved\"  # Use the improved architecture\n",
    "\n",
    "print(f\"Experiment: {config.name}\")\n",
    "print(f\"Description: {config.description}\")\n",
    "print(f\"Device: {config.system.device}\")\n",
    "print(f\"Model: {config.model.model_name}\")\n",
    "print(f\"Epochs: {config.training.epochs}\")\n",
    "print(f\"Batch size: {config.data.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Visualization\n",
    "\n",
    "Our improved data module handles all preprocessing and augmentation automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data module\n",
    "data_module = CIFAR10DataModule(\n",
    "    data_dir=config.data.data_dir,\n",
    "    batch_size=config.data.batch_size,\n",
    "    val_split=config.data.val_split,\n",
    "    num_workers=2,  # Reduced for notebook\n",
    "    pin_memory=False  # Disabled for notebook compatibility\n",
    ")\n",
    "\n",
    "# Get data loaders\n",
    "train_loader, val_loader, test_loader = data_module.get_dataloaders()\n",
    "\n",
    "print(f\"Training samples: {len(data_module.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(data_module.val_dataset)}\")\n",
    "print(f\"Test samples: {len(data_module.test_dataset)}\")\n",
    "print(f\"\\nCIFAR-10 classes: {data_module.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from training set\n",
    "show_sample_images(\n",
    "    train_loader, \n",
    "    num_images=8, \n",
    "    title=\"Sample Training Images (with augmentation)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from test set (no augmentation)\n",
    "show_sample_images(\n",
    "    test_loader, \n",
    "    num_images=8, \n",
    "    title=\"Sample Test Images (no augmentation)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "Let's examine our improved CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the improved model\n",
    "device = torch.device(config.system.device)\n",
    "model = get_model(\n",
    "    model_name=config.model.model_name,\n",
    "    num_classes=config.model.num_classes,\n",
    "    dropout_rate=config.model.dropout_rate\n",
    ")\n",
    "\n",
    "print(f\"Model architecture: {config.model.model_name}\")\n",
    "print(f\"\\nModel summary:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model with a sample batch\n",
    "model.eval()\n",
    "sample_batch, sample_labels = next(iter(test_loader))\n",
    "print(f\"Input shape: {sample_batch.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(sample_batch)\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = torch.softmax(output, dim=1)\n",
    "    print(f\"Probability range: [{probabilities.min():.3f}, {probabilities.max():.3f}]\")\n",
    "    print(f\"Probability sum (should be ~1.0): {probabilities[0].sum():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Setup\n",
    "\n",
    "Our training system includes modern optimizers, schedulers, and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer and scheduler\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.training.learning_rate,\n",
    "    weight_decay=config.training.weight_decay\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config.training.epochs\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = ModelTrainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: {type(optimizer).__name__}\")\n",
    "print(f\"Learning rate: {config.training.learning_rate}\")\n",
    "print(f\"Scheduler: {type(scheduler).__name__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Let's train our model with the professional training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=config.training.epochs,\n",
    "    save_best=True,\n",
    "    early_stopping_patience=5\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best validation accuracy: {trainer.best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Visualization\n",
    "\n",
    "Visualize the training progress with our improved plotting utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    train_losses=history['train_losses'],\n",
    "    val_losses=history['val_losses'],\n",
    "    val_accuracies=history['val_accuracies'],\n",
    "    learning_rates=history.get('learning_rates')\n",
    ")\n",
    "\n",
    "# Print training summary\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"Final training loss: {history['train_losses'][-1]:.4f}\")\n",
    "print(f\"Final validation loss: {history['val_losses'][-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {history['val_accuracies'][-1]:.2f}%\")\n",
    "print(f\"Best validation accuracy: {max(history['val_accuracies']):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Comprehensive evaluation with detailed metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_loader)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Test Loss: {test_results['test_loss']:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# Print per-class accuracies\n",
    "print(f\"\\nPer-class accuracies:\")\n",
    "for i, class_name in enumerate(data_module.classes):\n",
    "    acc = test_results['class_accuracies'][i]\n",
    "    print(f\"  {class_name}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "print(f\"Generated predictions for {len(all_predictions)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    y_true=all_targets,\n",
    "    y_pred=all_predictions,\n",
    "    class_names=data_module.classes,\n",
    "    title=\"Confusion Matrix - Improved CIFAR-10 CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model predictions\n",
    "visualize_predictions(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    num_samples=8,\n",
    "    class_names=data_module.classes,\n",
    "    title=\"Model Predictions on Test Images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Analysis\n",
    "\n",
    "Let's analyze the model's performance and compare it with the original implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Original Implementation:\")\n",
    "print(f\"  - Test Accuracy: 72.2%\")\n",
    "print(f\"  - Architecture: Simple CNN\")\n",
    "print(f\"  - Training: Basic setup\")\n",
    "print(f\"\")\n",
    "print(f\"Improved Implementation:\")\n",
    "print(f\"  - Test Accuracy: {test_results['test_accuracy']:.2f}%\")\n",
    "print(f\"  - Architecture: {config.model.model_name.title()} CNN\")\n",
    "print(f\"  - Training: Professional pipeline\")\n",
    "print(f\"  - Data Augmentation: Advanced\")\n",
    "print(f\"  - Regularization: Dropout + BatchNorm\")\n",
    "\n",
    "# Calculate improvement\n",
    "original_acc = 72.2\n",
    "current_acc = test_results['test_accuracy']\n",
    "improvement = current_acc - original_acc\n",
    "\n",
    "print(f\"\\nImprovement: {improvement:+.2f} percentage points\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"✅ The improved implementation performs better!\")\n",
    "elif improvement > -2:\n",
    "    print(\"📊 Similar performance with better code quality\")\n",
    "else:\n",
    "    print(\"⚠️ Performance may need tuning (try more epochs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Insights\n",
    "\n",
    "Analyze what the model learned and identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best and worst performing classes\n",
    "class_accs = [test_results['class_accuracies'][i] for i in range(10)]\n",
    "best_class_idx = np.argmax(class_accs)\n",
    "worst_class_idx = np.argmin(class_accs)\n",
    "\n",
    "print(f\"Model Performance Analysis:\")\n",
    "print(f\"=\" * 30)\n",
    "print(f\"Best performing class: {data_module.classes[best_class_idx]} ({class_accs[best_class_idx]:.2f}%)\")\n",
    "print(f\"Worst performing class: {data_module.classes[worst_class_idx]} ({class_accs[worst_class_idx]:.2f}%)\")\n",
    "print(f\"Performance gap: {class_accs[best_class_idx] - class_accs[worst_class_idx]:.2f} percentage points\")\n",
    "\n",
    "# Calculate confusion between similar classes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(all_targets, all_predictions)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Find most confused pairs\n",
    "print(f\"\\nMost confused class pairs:\")\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm_normalized[i, j] > 0.15:  # More than 15% confusion\n",
    "            print(f\"  {data_module.classes[i]} → {data_module.classes[j]}: {cm_normalized[i, j]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Saving and Loading Models\n",
    "\n",
    "Demonstrate how to save and load the trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "checkpoint_path = project_root / \"notebooks\" / \"demo_model.pth\"\n",
    "\n",
    "trainer.save_checkpoint(\n",
    "    filepath=str(checkpoint_path),\n",
    "    epoch=config.training.epochs,\n",
    "    config=config.to_dict(),\n",
    "    test_results=test_results\n",
    ")\n",
    "\n",
    "print(f\"Model saved to: {checkpoint_path}\")\n",
    "\n",
    "# Demonstrate loading\n",
    "print(\"\\nDemonstrating model loading...\")\n",
    "new_model = get_model(\n",
    "    model_name=config.model.model_name,\n",
    "    num_classes=config.model.num_classes,\n",
    "    dropout_rate=config.model.dropout_rate\n",
    ")\n",
    "\n",
    "new_trainer = ModelTrainer(model=new_model, device=device)\n",
    "loaded_checkpoint = new_trainer.load_checkpoint(str(checkpoint_path))\n",
    "\n",
    "print(f\"Model loaded successfully from epoch {loaded_checkpoint.get('epoch', 'unknown')}\")\n",
    "print(f\"Loaded best validation accuracy: {new_trainer.best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the significantly improved CIFAR-10 implementation with:\n",
    "\n",
    "### ✅ **Code Quality Improvements**\n",
    "- **Modular Design**: Clean separation of concerns\n",
    "- **Configuration Management**: Flexible experiment setup\n",
    "- **Professional Training Pipeline**: Modern PyTorch practices\n",
    "- **Comprehensive Evaluation**: Detailed analysis tools\n",
    "\n",
    "### 🚀 **Technical Improvements**\n",
    "- **Better Architecture**: Improved CNN with modern techniques\n",
    "- **Advanced Data Augmentation**: Robust preprocessing\n",
    "- **Smart Training**: Learning rate scheduling, early stopping\n",
    "- **Proper Normalization**: CIFAR-10 specific statistics\n",
    "\n",
    "### 📊 **Portfolio Readiness**\n",
    "- **Documentation**: Comprehensive README and comments\n",
    "- **Reproducibility**: Seed management and configuration\n",
    "- **Extensibility**: Easy to add new models and experiments\n",
    "- **Professional Structure**: Industry-standard organization\n",
    "\n",
    "### 🎯 **Next Steps for Portfolio**\n",
    "1. **Experiment with different architectures** (ResNet, EfficientNet)\n",
    "2. **Add transfer learning** capabilities\n",
    "3. **Implement hyperparameter optimization**\n",
    "4. **Create a web demo** with Streamlit or Gradio\n",
    "5. **Add model deployment** scripts\n",
    "\n",
    "This implementation showcases modern machine learning engineering practices and demonstrates your growth from the original Udacity project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}